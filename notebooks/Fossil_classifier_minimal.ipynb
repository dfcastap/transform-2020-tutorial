{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a fossil classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from [Swung's public Amazon S3 bucket](https://swung-data.s3.amazonaws.com/fossilnet/fossilnet-png-224px.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://swung-data.s3.amazonaws.com/fossilnet/fossilnet-png-224px.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "r = requests.get(data_url, stream=True)\n",
    "z = zipfile.ZipFile(BytesIO(r.content))\n",
    "z.extractall(path='..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 3000 PNG files there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l ../fossilnet-png-224px/*/*/*.png | wc | awk '{print $1 \" PNG files\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be aware of the licensing of these images. Note that it relies on the [_Fair use doctrine_](https://en.wikipedia.org/wiki/Fair_use) (also called _Fair dealing_) and that individual images are not open; only the collection is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown('../fossilnet-png-224px/fossilnet-copyright-info.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not trying to make a fantastic model here, and this is a hard dataset.\n",
    "\n",
    "So I'm only going to use `train` and `val`, and I'm only going to use 4 classes.\n",
    "\n",
    "Let's read the files, do a bit of processing on them (make greyscale and resize), and I'll also save a flipped version, so I'll have 2 versions of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def img_to_arr(img):\n",
    "    \"\"\"\n",
    "    Apply the same processing we used in training: greyscale and resize.\n",
    "    \"\"\"\n",
    "    img = img.convert(mode='L').resize((32, 32))\n",
    "    return np.asarray(img).ravel() / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sets = ['train', 'val']\n",
    "classes = ['trilobites', 'fishes', 'forams', 'dinosaurs']\n",
    "\n",
    "data = defaultdict(list)\n",
    "labels = defaultdict(list)\n",
    "\n",
    "for set_ in sets:\n",
    "    for class_ in classes:\n",
    "        for fname in glob(f'../fossilnet/{set_}/{class_}/*.png'):\n",
    "\n",
    "            img = Image.open(fname)\n",
    "            arr = img_to_arr(img)\n",
    "            data[set_].append(arr.ravel())\n",
    "            data[set_].append(np.fliplr(arr.reshape(32, 32)).ravel())\n",
    "            labels[set_] += 2 * [class_]\n",
    "\n",
    "X_train = np.array(data['train'])\n",
    "X_val = np.array(data['val'])\n",
    "\n",
    "y_train = np.array(labels['train'])\n",
    "y_val = np.array(labels['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data['train'][503].reshape(32, 32))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and evaluate a model\n",
    "\n",
    "A very simple model, with only 2 hyperparameters to ensure the trees can't overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=11,\n",
    "                             n_estimators=100,\n",
    "                             max_depth=5,\n",
    "                             min_samples_leaf=5)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "f1_score(y_train, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "f1_score(y_val, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit overtrained... let's worry about it later. Or maybe it's SEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's okay at forams, not great at dinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Now we can train on all the data so I'll concatenate the arrays together. (We have more data too, as we didn't use the `test` directory, but oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X_train, X_val])\n",
    "y = np.hstack([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=11,\n",
    "                             n_estimators=100,\n",
    "                             max_depth=5,\n",
    "                             min_samples_leaf=5)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, '../app/rf.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Make predictions from new images - using URL\n",
    "\n",
    "We'd like to use this trained model to make predictions from random images people throw at us. So we need a function to process those images to be exactly like the ones we trained on.\n",
    "\n",
    "Let's stick to using the same tool we used before: `skimage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import Image\n",
    "\n",
    "clf = joblib.load('../app/rf.gz')\n",
    "\n",
    "\n",
    "def fetch_image(url):\n",
    "    \"\"\"\n",
    "    Download an image from the web and pass to the image processing function.\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    f = BytesIO(r.content)\n",
    "    return Image.open(f) \n",
    "\n",
    "def predict_from_image(clf, img):\n",
    "    \"\"\"\n",
    "    Classify an image.\n",
    "    \"\"\"\n",
    "    arr = img_to_arr(img)\n",
    "    X = np.atleast_2d(arr)\n",
    "    probs = clf.predict_proba(X)\n",
    "    result = {\n",
    "        'class': clf.classes_[np.argmax(probs)],\n",
    "        'prob': probs.max(),\n",
    "        'classes': clf.classes_.tolist(),\n",
    "        'probs': np.squeeze(probs).tolist(), # Must be serializable.\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"examples.txt\") as f:\n",
    "    urls = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "\n",
    "IPython.display.Image(urls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_from_image(clf, fetch_image(urls[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t20-fri-mvp",
   "language": "python",
   "name": "t20-fri-mvp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
